
idea:  what about cases where we have lots of tombstones
but are not in a needs_merge state?  we want to get rid
of them anyway...

why do we have so many cases where any_node shows only
1 (or just a few) children to choose from when promoting?

why is the number of keys promoted always so small, even
when we are promoting 8 leaves?

do we need to dump timings of when the main thread is
waiting because merge need is desperate?

hmmm.  maybe we had the necessary_tombstone() code backwards.
consider NOT doing this check on merge from Fresh.  to make
it faster.  merge from fresh is imply to reduce the segment
count as quickly as possible by combining them together into
bigger segments in Young.

I wonder if we have problems where a fresh segment contains a
ton of tombstones that should be deleted but can't be because
it's the only fresh segment so needs_merge return false.
tried addressing this with a change to the settings, as an
experiment.

treating all fresh/young segments as the same size has gotta
be a problem.

weird:  the second run of the test suite currently is a lot
faster with the prepare_merge() expensive_check turned on.

weirder:  running 8 test runs in a row from a bash script
without a server restart:  with expensive_check off, several
failures, and quite slow.  with expensive_check on, no
failures, and faster.  (this was done with the promote N->N+1
code set to always choose one leaf).

needs_merge() probably needs some way to account for whether
reads are happening or not.  if it is purely writes, we have
less incentive to do merges.  if reads are happening, we should
get desperate faster.

too many tombstones getting left?  need a diag to find tombstones
that could have been dropped but were not?

what happened below?  is the startup list_all_blocks() code okay?
actually, this can happen without stopping/starting the server,
so list_all_blocks() is not in play.  it can also happen with
either a leaf or a parent page.

thread '<unnamed>' panicked at 'explicit panic', /Users/eric/dev/Elmo/lsm/src/lib.rs:4631
stack backtrace:
   1:        0x10bb14c30 - sys::backtrace::tracing::imp::write::hdcea88a6044f25a0c7s
   2:        0x10bb0ab82 - sys_common::unwind::begin_unwind_inner::ha0580f58a156b13e28r
   3:        0x10ba98744 - sys_common::unwind::begin_unwind::h1618399666050044516
   4:        0x10babb45c - LeafPage::parse_page::h844989bca426533aF6f
   5:        0x10bab366e - LeafPage::read_page::h8c43b2d678091577Ubg
   6:        0x10babd480 - PageCursor::read_page::h66798c706c1c7ac2evg
   7:        0x10babd3ef - PageCursor::read_page::h66798c706c1c7ac2evg
   8:        0x10baa02de - ParentCursor.IForwardCursor::Next::hb98be6463298992cnAh
   9:        0x10baa2e39 - MultiCursor.IForwardCursor::Next::hba116173610801f3TAc
  10:        0x10baa6c1f - LivingCursor::skipTombstonesForward::hca08ce25eb751ab1qdd
  11:        0x10baa80f5 - RangeCursor::Next::h1031ce63f5601f33nzd
  12:        0x10b94e2d8 - RangeCursorBsonValueIterator.Iterator::next::h0b899b538087344fkea
  13:        0x10b987815 - MyCollectionReader.Iterator::next::h7251dfba7c3adff1zfc
  14:        0x10ba406ce - iter::FilterMap<I, F>.Iterator::next::h11490810477968315499
  15:        0x10b9124b2 - iter::Iterator::count::h6329506342169373999
  16:        0x10b932a5b - Server<'b>::reply_cmd::h533c1789c23e1413idc

running the elmo test multiple times shows it getting
slower, and elmo list_indexes is a lot of the time,
and the worst culprit is MultiCursor::sort.  is the
segment list just getting too long?  lower the
Desperate threshold?

shouldn't MC::sort try to remember the orderings?
or can it?

part of the problem is in the elmo layer and in the
mongo tests.  a lot of indexes get left around after
each test run.  the elmo layer, when asked for a
collection writer, gets a list of all the indexes,
so this query gets slower the more indexes there are.
it should not need the list to update the primary index.
and if it is not constraining the index list by range,
it should be.

second run of test suite into same db is really slow.
probably fragmentation and blocklist stuff?  no.  second
run has LiveCursor skipping a thousand times as many
tombstones.

should the default page size be 4K or 8K ?

parent node writer gets in trouble, overflows its stack,
when it has to deal with lots of pages that only hold one
key.  problem is that if only one key fits in the leaf,
then only one key fits in its parent, so the generation
of parent nodes is the same size, so depth increases
forever.  maybe we need to overflow keys unless two of
them can fit in a parent page.  or maybe a parent page
needs the ability to overflow a key even if the leaf
did not, just to ensure that at least two keys fit in
every parent.

most of the largest merges are from Young to Other(0).  need
to be more careful about how much we merge from Young at
one time.

too many open/close of the file for PageWriter as well.

need to make merges more parallelizable.  two merges in
the same level but different key range.

maybe the level factor should be less than 10x so that the segments
stay smaller and so the blocklists stay smaller.  but then reads get
slower because more segments.  nonetheless, it is interesting to
note that the 5M URL test is MUCH faster when the factor is 2
instead of 10.  why?  It's just another way of deferring writes?

unless it needs to pass along an Arc clone, methods should
be &self not &Arc<InnerPart>

where should I be using AsRef?  From/Into ?

bufadvance and PageBuilder should use trait implementations 
for Read and Write on slices/vecs

vec capacities

can we have the segment page objects reference the buf in the
header instead of cloning it?  Arc<buf> ?  but then how do we deal
with ParentPage that wants to walk through all of its children without
realloc on each one?  separate implementations?  one form of the
page object borrows its buf (from the one in the SegmentHeaderInfo).
the other one owns its buf (so it can read a different page into it).

get rid of pagepool?

lots of bufadvance and varint read calls should probably return Result
so they can properly error on invalid pages read from the file.
or, when parsing a page, check before calling them.

so a new leaf can't squeeze between two parents anymore.
what does this mean for the merge problem where we had
parent nodes underfull and depth increasing to the right?

need to figure out a place to call truncate_file_if_possible()
every so often.

how to choose a page from the merge source when merging Other?
is a parent too big?  a leaf too small?  
rotate through the key space?

rm dead MultiPageCursor?  or will we need this later for cases
where we are merging from Other level N to N+1 and want to select 
more than a leaf and less then a parent?

removing the rewrite_level (which should be rewrite_depth)
code now shows that the depth increasing to the right
problem is mostly better, but perhaps not entirely.
the 5M url test doesn't show it unless the consecutive
nodes for recycle setting for depth 1 is at 1 instead of 2.

status quo (one prefix for the whole page)
prefix chain
fsa

KeyRef::Prefixed
search in page without uncompressing all keys
nth key
work to get one key
cost to build

status quo is the only one that supports KeyRef::Prefixed.
most forms of compression in general will require that
the key be constructed/allocated in order to return it
for a cursor.

prefix chain is probably cheaper to build than the others.
status quo sometimes needs to go back and recalc when the
prefix len changes.  fsa will be the most expensive to 
build, probably by far.

fsa will very nicely support search in the page without
decompressing all the keys.  status quo mostly does too.  
prefix chain will not.

prefix chain won't support nth key unless we decompress
them all.  fsa won't support nth key at all.  would need
to change all uses to something more like an iterator
model.

prefix chain is ugly for overflowed keys.  is the prefix
always referring to the previous key?  even if it was
overflowed?  if so, the overflowed key always has to be
read in order to construct any keys after it.

actually, fsa has trouble with overflowed keys too.
how does an overflowed key fit in there?

could maybe just alternate?  even number keys are stored
without prefix compression.  odds ones are prefixed against
the one just before it.

the following isn't true anymore:
tree of depth 4.  if you insert a key that fits between
everything, it will end up with its own very thin parent
lineage.  one leaf, a parent with only one child,
another parent with only one child, and so on.  eventually,
it will either fit under a parent where it fits, or it
will be a sibling, causing the depth to grow.  we look
at this from the perspective of always recycling a node
when we can, but we should probably be asking a different
question.  just because a new key will fit in between
two nodes, should it?  does the answer depend on the
level?  if a level has N nodes and it can stay at N
nodes with the new key added, shouldn't we rewrite
to avoid depth increasing?

that's what the newer rewrite_level code kinda does.
it ensures that at some point not too far up, we decide
to rewrite the level, to make sure we don't have this
problem.

write merge can be a little smarter and can start at the
top for recycling decisions.  basically, when rewriting
a parent, find all the child nodes that need to be rewritten
and rewrite them, but only to the depth they were at
before.  don't allow them to increase in depth.  this
means that each one might result in more than one after
the merge.  after that, combine them with the rest of
the child nodes (the ones recycled, not being rewritten),
and write a new parent, again stopping at the depth
we started with so we can return to the caller.

but this is kinda what ParentNodeWriter is supposed to do.
why doesn't it work that way?  maybe:  if we are currently
recycling nodes at N and then we have to rewrite one, we
need to continue at N, not jump to N + 1.

maybe we just need ParentNodeWriter to stop flushing the
current just because it got a recycle of something at a
higher depth.  just pass it along, but sort all the results
by key range on done().

the other thing ParentNodeWriter got us was not having to
keep all the leaves in memory.  it's more like a stream,
processing things as we go.

commit 5M urls in one transaction.  we will need ways of
dealing with large segments in fresh and young.  can't
promote whole segment.  writing segment would need to be
done in batches, but can't keep page in ram for lots of
batches.  in this sense, promote from young needs to be
not much different than promote from N.

and maybe promote from N to N+1 needs the ability to
leave N empty (edge case).

if we are rewriting a node, that means we could not or
chose not to recycle the parent of that node.

every time we recycle a node, we flush the current page
in progress, at every level, down to that node's depth.

do we have no test cases involving an overflowed key?

can we somehow get the blocklist to be smaller?  reduce fragmentation?
or is that simply a tradeoff with recycling?  in other words, if the
only way to reduce fragmentation is to rewrite more stuff during
merge, that's sad.

consider fsa for storing keys instead of prefix compression.
dependency on BurntSushi fst crate?  or just extract code
parts we need and adapt?

think about memmap for cursors

might want to send a Work message as soon as the db is
loaded.  unless it was opened in a read only mode.

should we keep track of "log" segments?  written but not
put into the header yet?  for recovery?

still need solution to monster block list.

file size explodes when multiple writers?  something
about pagewriter?  block size too big?  is pw.end getting
called?

at some point we should review which asserts we really want in release
builds and perf check without the rest of them.

avoiding rewrites of leaves has a downside:  once something is
high up in the file, it probably won't move, the file doesn't
shrink much, and ends up with a lot of empty blocks in it.

allow block allocation policy that always selects the earliest block?

maybe everywhere we read a page (cursors), instead of a file,
we should provide an object which abstracts the reading of page.
allows a cache.  or a non-file.

revisit when to check for tombstones during write_merge

lsm_diag should just have show_page

consider fiddling with the depth at which parent nodes
store child block lists.  more than just one?  do we
need them at all?  would need parent nodes fit calculations 
to account for the size of the encoded block lists.  
do we need this anyway?

look for ways to make elmo index entry encoding more compact

at some point, review all decisions about what actually gets stored
in the parent page and make sure it's worth it.  full
block list?  should we store the number of descendant leaves?

header can get really small.  so small that we no longer want to 
waste 4096 bytes or an entire page on it?  it would need to live on
a portion of the first page, with the rest available as a short
page for use by segments.  which means the PageWriter stuff needs
to know that not all pages are the same size (in terms of their
usable space).  and callers of PageWriter need to know how big
the next page is going to be.

do binary search of keys in the parent page like in the leaf?

not sure a parent page with only one item in it makes much sense

code for calc/build/write leaf and parent has gotten awfully similar

multiple prefixes, so we can have better compression of keys in
parent page?

any way to represent/store keys as deltas?  vcdiff?

need more tests of large overflows, especially with block allocation
issues, fragmentation, etc.

drop db needs to wait until threads end?  need a way to wait until
threads end?

tune block sizes for perf?

figure out proper limits for how much should be at each level.
currently using geometric like leveldb, sometimes with the
factor as low as 2.  lower multipler means faster writes and
slower reads.

update rust nightly?

separate lsm code into multiple files (modules) so we can get 
better privacy on struct fields

ability to merge entire file

ability to compact a file (write entire thing into one clean new file
with no free blocks)

diag_lsm:  dump level_sizes?  or is list_segments enough, since we
usually have only one segment per level?

implement a pending transaction manager.  allows crud operations.
accumulates them in a BTreeMap.  automatically flushes them out to
a pending segment when it gets too large.  automatically merges its
pending segments when there are more than one.  queries, automatically
putting its pending segment into the cursor.  notice when values
are actually stream and write them to disk so we don't have too
many files open.

need a function to get a cursor with a pending segment in front of it

ability to reserve a piece of each page for things like crypto

how much perf trouble is being caused by all these mutexes and Arcs?

fix fts in lsm storage

consider better (at higher level?) cache of elmo indexes

we're using usize all over the place for cases size and index into a page.
this is sad, because a page will never exceed 32 bits, and probably will
not exceed 16 bits.

make pgnum a u64?
same for pgnum but then storage is wasteful,
want to store as a varint, but then space in the page calculations are
more complicated.

reduce malloc

are we using Arc too much now?  are there places we could sweep back
through and replace Arc with &T ?

https://github.com/zslayton/lifeguard

cleanup bcmp and friends

vbuf reuse write leaves

keyInLeafs should share code.

same for Value and ValueRef code

want to write lint to disallow tabs?

perhaps, when reading stuff from a buffer, instead of using a cur variable,
we should use the Read impl of slice

the benefit of getting a reference to the key or value bytes directly
in the page will be diminished when the bytes are compressed or encrypted.

chg names back to Key and Value?

read bson value without alloc?  but then we need to give references into
the buffer, which might be big.  that's basically read bson value with
only one (big) alloc for the object itself.

TODO the cursor needs to expose the changeCounter and segment list
on which it is based. for optimistic writes.  caller can grab a cursor,
do their writes, then grab the writelock, and grab another cursor, then
compare the two cursors to see if anything important changed.  if not,
commit their writes.  if so, nevermind the written segments and start over.

